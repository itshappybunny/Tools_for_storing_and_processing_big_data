# Tools_for_storing_and_processing_big_data

## PRACTICAL WORKS 

## **[–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2.1. –ò–∑—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ NoSQL](https://github.com/itshappybunny/Tools_for_storing_and_processing_big_data/blob/main/2.1_%D0%9B%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0.pdf)**


## **[–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3.1. –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö](https://github.com/itshappybunny/Tools_for_storing_and_processing_big_data/blob/main/3.1_%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B_%D1%85%D1%80%D0%B0%D0%BD%D0%B8%D0%BB%D0%B8%D1%89%D0%B0_%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D1%85_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.pdf)**


## **–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4.1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤ —Ö—Ä–∞–Ω–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö**


## **–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5.1. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ Hadoop**


## **–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6.1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Apache Spark**


# ---------------------------------------------------------
# –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–ù–ù–´–• –î–õ–Ø –ü–†–û–ï–ö–¢–û–í –ò –ó–ê–î–ê–ß (PostgreSQL + MongoDB)
# ---------------------------------------------------------

faker = Faker()
np.random.seed(42)

# –û–±—ä—ë–º—ã –¥–∞–Ω–Ω—ã—Ö
n_projects = 10000      # –æ–±—ã—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
n_tasks = 100000        # –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ

print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö:")
print(f"- –ü—Ä–æ–µ–∫—Ç–æ–≤: {n_projects:,}")
print(f"- –ó–∞–¥–∞—á: {n_tasks:,}")

# ---------------------------------------------------------
# 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤
# ---------------------------------------------------------

projects_data = []
for i in range(n_projects):
    projects_data.append({
        "project_id": i,
        "name": f"Project_{i:05d}",
        "description": faker.sentence(),
        "created_at": faker.date_time_between(start_date="-2y", end_date="now")
    })

projects_df = pd.DataFrame(projects_data)

# ---------------------------------------------------------
# 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á
# ---------------------------------------------------------

statuses = ["–Ω–æ–≤–∞—è", "–≤ —Ä–∞–±–æ—Ç–µ", "—Å—Ä–æ—á–Ω–æ", "–∑–∞–≤–µ—Ä—à–µ–Ω–∞"]

tasks_data = []
for i in range(n_tasks):
    tasks_data.append({
        "task_id": i,
        "project_id": np.random.randint(0, n_projects),
        "title": f"Task_{i:06d}",
        "status": np.random.choice(statuses, p=[0.4, 0.3, 0.05, 0.25]),  # 5% –∑–∞–¥–∞—á ‚Äî "—Å—Ä–æ—á–Ω–æ"
        "deadline": faker.date_time_between(start_date="now", end_date="+30d")
    })

tasks_df = pd.DataFrame(tasks_data)

print("\n–°–æ–∑–¥–∞–Ω—ã DataFrame:")
print(f"- projects_df: {len(projects_df):,} –∑–∞–ø–∏—Å–µ–π")
print(f"- tasks_df: {len(tasks_df):,} –∑–∞–ø–∏—Å–µ–π")

display(projects_df.head())
display(tasks_df.head())


# ---------------------------------------------------------
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV —Ñ–∞–π–ª—ã
# ---------------------------------------------------------

projects_df.to_csv("projects.csv", index=False)
tasks_df.to_csv("tasks.csv", index=False)

print("‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV:")
print("- projects.csv")
print("- tasks.csv")

# ---------------------------------------------------------
# üìä –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•
# ---------------------------------------------------------

print("\nüìä –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö:")

tasks_per_project = tasks_df.groupby("project_id").size()

print(f"- –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –Ω–∞ –ø—Ä–æ–µ–∫—Ç: {tasks_per_project.mean():.2f}")
print(f"- –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –≤ –ø—Ä–æ–µ–∫—Ç–µ: {tasks_per_project.min()}")
print(f"- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –≤ –ø—Ä–æ–µ–∫—Ç–µ: {tasks_per_project.max()}")

urgent_count = (tasks_df["status"] == "—Å—Ä–æ—á–Ω–æ").sum()
print(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º '—Å—Ä–æ—á–Ω–æ': {urgent_count:,}")
print(f"- –î–æ–ª—è —Å—Ä–æ—á–Ω—ã—Ö –∑–∞–¥–∞—á: {urgent_count / len(tasks_df) * 100:.2f}%")

# –¢–æ–ø-10 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
top_projects = tasks_per_project.sort_values(ascending=False).head(10)
print("\nüî• –¢–æ–ø-10 –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–∞–¥–∞—á:")
for pid, count in top_projects.items():
    pname = projects_df.loc[projects_df["project_id"] == pid, "name"].iloc[0]
    print(f"  {pname}: {count} –∑–∞–¥–∞—á")

# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –∑–∞–¥–∞—á
status_distribution = tasks_df["status"].value_counts(normalize=True) * 100
print("\nüìå –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –∑–∞–¥–∞—á (%):")
for status, pct in status_distribution.items():
    print(f"  {status}: {pct:.2f}%")


# ---------------------------------------------------------
# 3. –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–• –î–õ–Ø MONGODB (–≤–ª–æ–∂–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã)
# ---------------------------------------------------------

print("\n–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è MongoDB...")

# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–¥–∞—á –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º
tasks_grouped = tasks_df.groupby("project_id")

projects_mongo = []

for _, project in projects_df.iterrows():
    pid = project["project_id"]

    project_doc = {
        "project_id": int(pid),
        "name": project["name"],
        "description": project["description"],
        "created_at": project["created_at"],
        "tasks": tasks_grouped.get_group(pid)
                 .drop(columns=["project_id"])
                 .to_dict("records") if pid in tasks_grouped.groups else []
    }

    projects_mongo.append(project_doc)

print(f"‚úî –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è MongoDB: {len(projects_mongo):,}")
print("–ü—Ä–∏–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞:")
projects_mongo[0]
